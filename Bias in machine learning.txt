In the "Bias in machine learning" section I learned about the types of machine learning. There is reinforcement learning, unsupervised machine learning, and supervised machine learning. I also learned about neural networks and the general concept behind machine learning. Machine learning algorithms trained on historical data can perpetuate biases that are already present in current society. An example of this is in the criminal justice sector, risk assessment algorithms have been found to exhibit racial bias due to hitorical arrest rates. Similarly, in the hiring processes, automated screenings have shown gender bias. These biases often are skewed from the data they are fed which is from human judgement and decision making. We also learned facial recognition exhibit biases. These biases can have serious implications including false arrests which highlight the need for 2 factor review from humans. NMT ( Neural machine translation) algorithms offer translation to different languages. However, these algorithms can show biases within the training data such as masculinity and femininity and other such minute details. 